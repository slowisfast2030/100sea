{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1. Strategies to scale computationally: bigger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor some applications the amount of examples, \\nfeatures (or both) and/or the speed at which they need to be processed are challenging for traditional approaches. \\nIn these cases scikit-learn has a number of options you can consider to make your system scale.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For some applications the amount of examples, \n",
    "features (or both) and/or the speed at which they need to be processed are challenging for traditional approaches. \n",
    "In these cases scikit-learn has a number of options you can consider to make your system scale.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2. Computational Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor some applications the performance (mainly latency and throughput at prediction time) of estimators is crucial. \\nIt may also be of interest to consider the training throughput but this is often less important in a production setup (where it often takes place offline).\\n\\nPrediction latency is measured as the elapsed time necessary to make a prediction (e.g. in micro-seconds). \\nLatency is often viewed as a distribution and operations engineers often focus on the latency at a given percentile of this distribution (e.g. the 90 percentile).\\n\\nPrediction throughput is defined as the number of predictions the software can deliver in a given amount of time (e.g. in predictions per second).\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For some applications the performance (mainly latency and throughput at prediction time) of estimators is crucial. \n",
    "It may also be of interest to consider the training throughput but this is often less important in a production setup (where it often takes place offline).\n",
    "\n",
    "Prediction latency is measured as the elapsed time necessary to make a prediction (e.g. in micro-seconds). \n",
    "Latency is often viewed as a distribution and operations engineers often focus on the latency at a given percentile of this distribution (e.g. the 90 percentile).\n",
    "\n",
    "Prediction throughput is defined as the number of predictions the software can deliver in a given amount of time (e.g. in predictions per second).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3. Parallelism, resource management, and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSome scikit-learn estimators and utilities can parallelize costly operations using multiple CPU cores, thanks to the following components:\\n\\n* via the joblib library. In this case the number of threads or processes can be controlled with the n_jobs parameter.\\n* via OpenMP, used in C or Cython code.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Some scikit-learn estimators and utilities can parallelize costly operations using multiple CPU cores, thanks to the following components:\n",
    "\n",
    "* via the joblib library. In this case the number of threads or processes can be controlled with the n_jobs parameter.\n",
    "* via OpenMP, used in C or Cython code.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
